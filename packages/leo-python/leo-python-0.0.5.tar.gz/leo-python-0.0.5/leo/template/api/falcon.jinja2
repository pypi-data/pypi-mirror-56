import logging
import marshmallow as ma
import falcon
import json
from typing import Mapping, Any, Optional

{% if use_elk %}
import logstash
{% endif %}

{% if use_prometheus %}
from prometheus_client import Summary, Counter
{% elif use_graphite %}
import graphyte
from .metrics import log_request_metrics
{% endif %}

from .model import BaseModel
from .modelrepo import ModelRepo, ModelException
from .schema import {{ project_name }}RequestSchema, {{ project_name }}ResponseSchema
{% if use_pyspark %}
from .spark_util import SparkUtil
{% if use_pyspark %}

logger = logging.getLogger('{{ project_name }}')
logger.setLevel(logging.INFO)
{% if use_elk -%}logger.addHandler(logstash.TCPLogstashHandler('{{ module_name }}-logstash-service', 5959, version=1)){%- endif %}

{% if use_prometheus %}
namespace = '{{ name }}'
RESPONSE_TIME = Summary(name='response_time_seconds', documentation='Response time for each request', namespace=namespace)
ERROR_COUNTER = Counter(name='failed_requests', documentation='Failed requests', labelnames=['exception_type'], namespace=namespace)
{% elif use_graphite %}
graphyte.init('{{ module_name }}-graphite-service', prefix='{{ module_name }}')
{% endif %}


def set_response(resp: falcon.Response, results: str, status: Optional[int] = None) -> None:
    """
    Sets the important fields in a Falcon Response.

    :param resp: The response to set.
    :param results: The main results to return.
    :param status: The status code for the response. This should be a valid HTTP response code. Defaults to 200.

    """

    if status is not None and hasattr(falcon, f'HTTP_{status}'):
        falcon_status = getattr(falcon, f'HTTP_{status}')
    else:
        falcon_status = falcon.HTTP_500
        results += f'\nIn addition, an attempt was made to set an invalid status code for this response: {status}'

    resp.status = falcon_status
    resp.body = json.dumps({
        'results': results
    })
    resp.append_header('Content-Type', 'application/json')


class RequestSchema(ma.Schema):
    """
    The schema for POST requests to the prediction method.
    """

    inputs = ma.fields.Nested({{ name }}RequestSchema(many=True), required=True)


class ResponseSchema({{ name }}ResponseSchema):
    """
    The schema for the responses.
    """


class _{{ name }}App:
    """
    The main API implementation.
    """

    schema = RequestSchema()

    def __init__(self):
        super().__init__()
        self._model = None
        {% if use_pyspark %}
        self._spark = SparkUtil().get_spark_session()
        {% endif %}

    def _get_model(self):
        """
        Lazy loaded model
        :return: Model instance
        """
        if self._model is None:
            self._model = ModelRepo().load_model()
        return self._model

    {% if use_prometheus %}
    @RESPONSE_TIME.time()
    {% elif use_graphite %}
    @log_request_metrics('predict')
    {% endif %}
    def on_post(self, req, resp):
        """
        Invoke the {{ name }}Model model.

        Calls underlying model prediction with given output and returns the predictions
        ---

        """
        args = req.context['json']
        logger.info(f'Querying {{ name }} with {args}.')
        try:
            results = self._get_model().do_predict({% if use_pyspark %}self._spark, {% endif %} args['inputs'])
            set_response(resp, results, 200)
        except ModelException as ex:
            logger.exception(ex)
            {% if use_prometheus %}
            ERROR_COUNTER.labels(ex.__class__.__name__).inc()
            {% endif %}
            set_response(resp, ex.msg, 400)


{{ name }}App = _{{ name }}App()

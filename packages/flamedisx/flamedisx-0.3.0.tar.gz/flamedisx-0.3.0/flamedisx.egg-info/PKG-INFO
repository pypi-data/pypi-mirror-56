Metadata-Version: 2.1
Name: flamedisx
Version: 0.3.0
Summary: Fast likelihood analysis in more dimensions for xenon TPCs
Home-page: https://github.com/JelleAalbers/flamedisx
Author: Jelle Aalbers, Bart Pelssers, Cristian Antochi
License: UNKNOWN
Description: Flamedisx
        ==========
        
        Fast likelihood analysis in more dimensions for xenon TPCs.
        
        [![Build Status](https://travis-ci.org/FlamTeam/flamedisx.svg?branch=master)](https://travis-ci.org/FlamTeam/flamedisx)
        [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3524865.svg)](https://doi.org/10.5281/zenodo.3524865)
        
        By Jelle Aalbers, Bart Pelssers, and Cristian Antochi
        
        Description
        -------------
        
        Flamedisx aims to increase the practical number of dimensions (e.g. s1, s2, x, 
        y, z and time) and parameters (g1, g2, recombination model coefficients, 
        electron lifetime, ...) in LXe TPC likelihoods.
        
        Traditionally, we evaluate (the probability density functions used in) our likelihoods using histograms created from high-statistics MC simulations. We precompute these histograms for several parameter combinations, then interpolate between them during inference ("vertical template morphing" in collider physics jargon). The precomputation time is exponential in the number of likelihood/histogram dimensions *and* the number of parameters used.
        
        Flamedisx instead computes the probability density directly at each observed event, without using MC integration (or approximating the model). The commonly used LXe emission model is simple enough that the integral equivalent to an MC simulation can be computed with a few matrix multiplications, at a speed of a few ms -- instead of a high-statistics MC simulation that takes O(minute) or more.
        
        This has several advantages:
          - Each event has its "private" detector model computation at the observed (x, y, z, time), so making the likelihood time- and position dependent incurs no additional computational burden. 
          - The likelihood for a dataset takes O(seconds) to compute, so we can do this at each of optimizer's proposed points during inference. We thus remove the precomputation step exponential in the number of parameters -- and can thus fit a great deal more parameters.
          - Since the likelihood consists of deterministic matrix multiplications, it can be implemented in tensorflow. This enables automatic differentiation, which unlocks the gradient during minimizing, drastically reducing the number of needed interactions for a fit or profile likelihood.
          
        Note this is under construction, so it probably has some bugs and little documentation.
        
        
        
        
        0.3.0 / 2019-11-19
        ------------------
        - Split off notebook folder to flamedisx-notebooks
        - Pass source specific parameters correctly (#51)
        - Flexible event padding (#54)
        - SciPy optimizer and optimizer settings (#54)
        - one_parameter_interval (#54)
        - Bugfixes (#46, #55, #51)
        - Unify optimizers (#54)
        
        0.2.2 / 2019-10-30
        ------------------
        - Minuit optimizer (#40)
        - Likelihood simulator (#43, #44)
        - Updates to NRSource (#40)
        
        0.2.1 / 2019-10-24
        ------------------
        - Workaround for numerical errors (#38, #39)
        
        0.2.0 / 2019-10-11
        ------------------
        - Spatially dependent rates (#27)
        - Time dependent energy spectra (#24)
        - XENON1T SR1-like model / fixes (#22, #32)
        - Switch optimizer to BFGS + Hessian (#19)
        - Multiple source support (#14)
        - Optimization (#13)
        - Bugfixes / refactor (#18, #20, #21, #28, #30, #31, #35)
        
        0.1.2 / 2019-07-24
        -------------------
        - Speedup ER computation, add tutorial (#11)
        - Optimize lookup-axis1 (#10)
        
        0.1.1 / 2019-07-21
        -------------------
        - 5x speedup for Hessian (#9)
        - Fix pip install
        
        0.1.0 / 2019-07-16
        -------------------
        - Batching (#7)
        - Inference (#6)
        - Ported to tensorflow / GPU support (#1, #2, #3, #5)
        
        0.0.1 / 2019-03-17
        ------------------
        - Initial numpy-based version
        
Platform: UNKNOWN
Classifier: Development Status :: 2 - Pre-Alpha
Classifier: License :: OSI Approved :: BSD License
Classifier: Natural Language :: English
Classifier: Programming Language :: Python :: 3.6
Classifier: Intended Audience :: Science/Research
Classifier: Programming Language :: Python :: Implementation :: CPython
Classifier: Topic :: Scientific/Engineering :: Physics
Requires-Python: >=3.6
Description-Content-Type: text/markdown

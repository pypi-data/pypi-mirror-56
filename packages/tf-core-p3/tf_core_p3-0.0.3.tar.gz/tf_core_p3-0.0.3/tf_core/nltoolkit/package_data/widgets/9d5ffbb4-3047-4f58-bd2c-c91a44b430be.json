[
  {
    "model": "workflows.abstractwidget", 
    "fields": {
      "category": "b0ce2ce4-16e8-4f9c-9874-238066c20fea", 
      "treeview_image": "", 
      "name": "Punkt Sentence Tokenizer", 
      "is_streaming": false, 
      "uid": "9d5ffbb4-3047-4f58-bd2c-c91a44b430be", 
      "interaction_view": "", 
      "image": "", 
      "package": "tf_core.nltoolkit", 
      "static_image": "token_word_image.png", 
      "windows_queue": false, 
      "post_interact_action": "", 
      "visualization_view": "", 
      "streaming_visualization_view": "", 
      "action": "nltk_punkt_sentence_tokenizer", 
      "wsdl_method": "", 
      "wsdl": "", 
      "interactive": false, 
      "has_progress_bar": false, 
      "order": 6, 
      "description": "A sentence tokenizer which uses an unsupervised algorithm to build a model for abbreviation words, collocations, and words that start sentences; and then uses that model to find sentence boundaries. This approach has been shown to work well for many European languages."
    }
  }, 
  {
    "model": "workflows.abstractoutput", 
    "fields": {
      "widget": "9d5ffbb4-3047-4f58-bd2c-c91a44b430be", 
      "name": "Tokenizer", 
      "short_name": "tkn", 
      "variable": "tokenizer", 
      "uid": "afe78641-95a9-4169-a94f-8856e201f6b1", 
      "order": 1, 
      "description": "A python dictionary containing the Tokenizer object and its arguments."
    }
  }
]
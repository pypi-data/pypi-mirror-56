[
  {
    "model": "workflows.abstractwidget", 
    "fields": {
      "category": "b0ce2ce4-16e8-4f9c-9874-238066c20fea", 
      "treeview_image": "", 
      "name": "Line Tokenizer", 
      "is_streaming": false, 
      "uid": "90d1e604-c3a5-452a-939e-067331c3e502", 
      "interaction_view": "", 
      "image": "", 
      "package": "tf_core.nltoolkit", 
      "static_image": "token_word_image.png", 
      "windows_queue": false, 
      "post_interact_action": "", 
      "visualization_view": "", 
      "streaming_visualization_view": "", 
      "action": "nltk_line_tokenizer", 
      "wsdl_method": "", 
      "wsdl": "", 
      "interactive": false, 
      "has_progress_bar": false, 
      "order": 1, 
      "description": "Tokenize a string into its lines, optionally discarding blank lines."
    }
  }, 
  {
    "model": "workflows.abstractinput", 
    "fields": {
      "widget": "90d1e604-c3a5-452a-939e-067331c3e502", 
      "name": "Blank Lines", 
      "short_name": "bln", 
      "uid": "e68b25ab-30f2-468b-b4f4-1eda4b22bca3", 
      "default": "discard", 
      "required": true, 
      "multi": false, 
      "parameter_type": "select", 
      "variable": "blanklines", 
      "parameter": true, 
      "order": 1, 
      "description": "blanklines: Indicates how blank lines should be handled.  Options are:\r\n        - discard: strip blank lines out of the token list before returning it.\r\n           A line is considered blank if it contains only whitespace characters.\r\n        - keep: leave all blank lines in the token list.\r\n        - discard-eof: if the string ends with a newline, then do not generate\r\n           a corresponding token ``''`` after that newline."
    }
  }, 
  {
    "model": "workflows.abstractoutput", 
    "fields": {
      "widget": "90d1e604-c3a5-452a-939e-067331c3e502", 
      "name": "Tokenizer", 
      "short_name": "tkn", 
      "variable": "tokenizer", 
      "uid": "51f31143-2d1e-4605-8b62-c9895dc85bfe", 
      "order": 1, 
      "description": "A python dictionary containing the Tokenizer object and its arguments."
    }
  }, 
  {
    "model": "workflows.abstractoption", 
    "fields": {
      "uid": "770b5df2-d493-4e91-9b9b-d3c35949ee40", 
      "abstract_input": "e68b25ab-30f2-468b-b4f4-1eda4b22bca3", 
      "value": "discard-eof", 
      "name": "discard-eof"
    }
  }, 
  {
    "model": "workflows.abstractoption", 
    "fields": {
      "uid": "9ddcd23f-6e73-4e71-8a06-6de7007b4500", 
      "abstract_input": "e68b25ab-30f2-468b-b4f4-1eda4b22bca3", 
      "value": "discard", 
      "name": "discard"
    }
  }, 
  {
    "model": "workflows.abstractoption", 
    "fields": {
      "uid": "f3a99f3b-07a8-400f-acde-1ca663664b45", 
      "abstract_input": "e68b25ab-30f2-468b-b4f4-1eda4b22bca3", 
      "value": "keep", 
      "name": "keep"
    }
  }
]
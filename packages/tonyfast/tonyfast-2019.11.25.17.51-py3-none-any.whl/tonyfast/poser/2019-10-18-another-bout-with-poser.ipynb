{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`λ` is an `object` for fluent function composition in `\"python\"` based on the `toolz` library.\n",
    "\n",
    "1.  [__Motivation__](#Motivation)\n",
    "2. [__Source__](#Source)\n",
    "3. [__Tests__](#Tests)\n",
    "\n",
    "#### Motivation\n",
    "\n",
    "[Function composition](https://en.wikipedia.org/wiki/Function_composition) is a common task in mathematics and modern programming.\n",
    "Object oriented function composition often breaks with conventional representations.\n",
    "The `toolz` library provides a set of functional programming objects to `compose` and `pipe` functions together.\n",
    "`compose` and `pipe` are top level composition functions that how two different typographic conventions.\n",
    "\n",
    "In the `toolz` example, both `f and g` are the same\n",
    "\n",
    "1. `compose` mimics a symbollic function composition.\n",
    "\n",
    "        f = compose(type, len, range)\n",
    "    \n",
    "1. `pipe` allows a fluent composition.\n",
    "\n",
    "        g = lambda x: pipe(x, range, len, type)\n",
    "        def h(x: int) -> type: return pipe(x, range, len, type)\n",
    "        \n",
    "The typology of the `compose` composition is destructive to the flow of literature because it must be read `reversed`. \n",
    "`pipe` on the other hand supplements the narrative providing literate compositions aligned with the direction of the literature.\n",
    "\n",
    "From a learning perspective, my experience with `poser` & its predecessors have taught me a lot about the pythonic data model.\n",
    "`Compose` expresses a near complete symbollic API for function composition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import toolz, abc, inspect, functools, typing, importlib, urllib, builtins, json, pathlib, operator, itertools, fnmatch\n",
    "    from toolz.curried import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Compose` augments `toolz.Compose` to provide a fluent & symbollic object for function composition in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "    class Compose(toolz.functoolz.Compose):\n",
    "        __slots__ = toolz.functoolz.Compose.__slots__ + tuple(\"args kwargs exceptions\".split())\n",
    "        def __init__(self, funcs=None, *args, **kwargs): \n",
    "            \"\"\"`Compose` stores `args` and `kwargs` like a partial.\"\"\"\n",
    "            super().__init__(funcs or (I,)); self.args, self.exceptions, self.kwargs = args, kwargs.pop('exceptions', tuple()), kwargs\n",
    "            \n",
    "        def __call__(self, *args, **kwargs):\n",
    "            args, kwargs = self.args + args, {**self.kwargs, **kwargs}\n",
    "            for callable in (self.first,) + self.funcs: \n",
    "                try: args, kwargs = (callable(*args, **kwargs),), {}; object = args[0]\n",
    "                except self.exceptions as Exception: return Ø(Exception)\n",
    "            return object\n",
    "        compute = __call__        \n",
    "        \n",
    "        \"\"\"`__add__ or pipe` a function into the composition.\"\"\"  \n",
    "        def pipe(this, object=None, *args, **kwargs):\n",
    "            \"\"\"`append` an `object` to `this` composition.\"\"\"\n",
    "            if isinstance(this, type) and issubclass(this, Compose): this = this()\n",
    "            if object == slice(None): return this\n",
    "            if isinstance(object, typing.Hashable):\n",
    "                if object in {True, 1}: return this.on()\n",
    "                if object in {False, 0}: return this.off()\n",
    "            if not object: return this\n",
    "            object = juxt(forward(object))\n",
    "            if args or kwargs: object = toolz.partial(object, *args, **kwargs)\n",
    "            if this.first == I: this.first = object\n",
    "            else: this.funcs += object,\n",
    "            return this\n",
    "        __add__ = __radd__ = __iadd__ = __getitem__ = pipe\n",
    "        \n",
    "        def extend(this, *object):\n",
    "            for object in object: this = this[object]\n",
    "            else: return this\n",
    "                \n",
    "        def skip(this, *args, **kwargs): \n",
    "            \"\"\"Don't append an object, for modifying compositions interactively.\"\"\"\n",
    "            return this[:]\n",
    "        __sub__ = __rsub__ = __isub__ = skip\n",
    "        \n",
    "        \"\"\"Feature flags\"\"\"\n",
    "        def on(this): return this\n",
    "        def off(this):\n",
    "            if this.funcs: this.funcs = this.funcs[:-1]\n",
    "            else: this.first = I\n",
    "            return this\n",
    "        \n",
    "        \"\"\"Mapping, Filtering, Groupby, and Reduction.\"\"\"\n",
    "        def map(this, callable, key=None): return this[toolz.partial(map, juxt(callable), key=juxt(key))]\n",
    "        __mul__ = __rmul__ = __imul__ = map\n",
    "        \n",
    "        def filter(this, callable, key=None): return this[toolz.partial(filter, juxt(callable), key=juxt(key))]\n",
    "        __truediv__ = __rtruediv__ = __itruediv__ = filter\n",
    "        \n",
    "        def groupby(this, callable): return this[toolz.curried.groupby(juxt(callable))]\n",
    "        __matmul__ = __rmatmul__ = __imatmul__ = groupby\n",
    "        \n",
    "        def reduce(this, callable): return this[toolz.curried.reduce(juxt(callable))]\n",
    "        __mod__ = __rmod__ = __imod__ = reduce\n",
    "        \n",
    "        \"\"\"Conditionals.\"\"\"\n",
    "        def excepts(this, *Exceptions): return λ(excepts=Exceptions)[this]\n",
    "        __xor__ = excepts\n",
    "        \n",
    "        def ifthen(this, callable): return IfThen(this[callable])\n",
    "        __and__ = ifthen\n",
    "        \n",
    "        def ifnot(this, callable): return IfNot(this[callable])\n",
    "        __or__ = ifnot\n",
    "        \n",
    "        \"\"\"Helpers\"\"\"\n",
    "        def isinstance(this, type): return IfThen(this[toolz.partial(toolz.flip(isinstance), type)])\n",
    "        __pow__ = __ipow__ = isinstance\n",
    "        \n",
    "        def do(this, callable): return this[toolz.curried.do(juxt(callable))]\n",
    "        __lshift__ = do\n",
    "                \n",
    "        def complement(this, object=None): return λ[toolz.complement(this)] if object == None else self[toolz.complement(object)]\n",
    "        __invert__ = complement\n",
    "        \n",
    "        \"\"\"Object tools\"\"\"\n",
    "        def attrgetter(this, *args, **kwargs): return this[operator.attrgetter(*args, **kwargs)]\n",
    "        def itemgetter(this, *args, **kwargs): return this[operator.itemgetter(*args, **kwargs)]\n",
    "        def methodcaller(this, *args, **kwargs): return this[operator.methodcaller(*args, **kwargs)]\n",
    "        \n",
    "        \"\"\"File tools\"\"\"\n",
    "        def read(this, *args, **kwargs): return this.pipe(read, *args, **kwargs)\n",
    "        __pos__ = read\n",
    "        \n",
    "        def write(this, file): return this.do(toolz.curried.flip(write)(file))\n",
    "        __rshift__ = write\n",
    "    \n",
    "        def dumps(this, **kwargs): return this[json.dumps]\n",
    "        __neg__ = dumps        \n",
    "        \n",
    "        def read_text(this): return this[pathlib.Path][pathlib.Path.read_text]\n",
    "        def read_bytes(this): return this[pathlib.Path][pathlib.Path.read_bytes]\n",
    "        \n",
    "        \"\"\"Directory tools\"\"\"\n",
    "        def glob(this, pattern): return this[pathlib.Path][toolz.curried.flip(pathlib.Path.glob)(pattern)]\n",
    "        def rglob(this, pattern): return this[pathlib.Path][toolz.curried.flip(pathlib.Path.rglob)(pattern)]\n",
    "        \n",
    "        def get(this, *args, **kwargs): return this.pipe(__import__('requests').get, *args, **kwargs)\n",
    "        def json(this, *args, **kwargs): return this[__import__('requests').Response.json]\n",
    "        def text(this, *args, **kwargs): return this.attrgetter('text')\n",
    "        \n",
    "        def frame(this, *args, **kwargs): return this[__import__('pandas').DataFrame]\n",
    "        def series(this, *args, **kwargs): return this[__import__('pandas').Series]\n",
    "        \n",
    "        def git(this, *args, **kwargs): return this[__import__('git').Repo]\n",
    "        def fnmatch(this, pattern): return this[toolz.curried.flip(fnmatch.fnmatch)(pattern)]\n",
    "        \n",
    "    class Conditional(Compose):\n",
    "        def __init__(self, predicate, *args, **kwargs):\n",
    "            self.predicate = super().__init__(*args, **kwargs) or predicate\n",
    "            \n",
    "    class IfThen(Conditional):\n",
    "        def __call__(self, *args, **kwargs):\n",
    "            object = self.predicate(*args, **kwargs)\n",
    "            return super().__call__(*args, **kwargs) if object else object\n",
    "        \n",
    "    class IfNot(Conditional):\n",
    "        def __call__(self, *args, **kwargs):\n",
    "            object = self.predicate(*args, **kwargs)\n",
    "            return object if object else super().__call__(*args, **kwargs)\n",
    "\n",
    "    try: import IPython\n",
    "    except: IPython = None\n",
    "    else: \n",
    "        for key, value in toolz.merge(\n",
    "            toolz.pipe(toolz, vars, toolz.curried.valfilter(callable), toolz.curried.keyfilter(toolz.compose(str.islower, toolz.first))),\n",
    "            toolz.pipe(builtins, vars, toolz.curried.valfilter(callable), toolz.curried.keyfilter(toolz.compose(str.islower, toolz.first))),\n",
    "            {} if IPython is None else toolz.pipe(IPython.display, vars, toolz.curried.valfilter(callable), toolz.curried.keyfilter(toolz.compose(str.isalpha, toolz.first)))).items(): \n",
    "            if not hasattr(Compose, key): \n",
    "                setattr(Compose, key, getattr(Compose, key, functools.partialmethod(Compose.pipe, value)))\n",
    "                getattr(Compose, key).__doc__ = inspect.getdoc(value)\n",
    "    \n",
    "    class Type(abc.ABCMeta): \n",
    "        def __getattribute__(cls, str):\n",
    "            if str in _type_method_names: return object.__getattribute__(cls, str)\n",
    "            return object.__getattribute__(cls(), str)\n",
    "        \n",
    "    _type_method_names = set(dir(Type))        \n",
    "    for attr in set(dir(Compose))-(set(dir(toolz.functoolz.Compose)))-set(\"__weakref__ __dict__\".split()): \n",
    "        setattr(Type, attr, getattr(Type, attr, getattr(Compose, attr)))\n",
    "        \n",
    "    class λ(Compose, metaclass=Type): \n",
    "        def __init__(self, *args, **kwargs): super().__init__(None, *args, **kwargs)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we have to write our own utility functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def I(*args, **kwargs): \"A nothing special identity function, does pep8 peph8 me?\"; return args[0] if args else None\n",
    "    def forward(module, *, property='', period='.'):\n",
    "        \"\"\"Load string forward references\"\"\"\n",
    "        if not isinstance(module, str): return module\n",
    "        while period:\n",
    "            try:\n",
    "                if not property: raise ModuleNotFoundError\n",
    "                return operator.attrgetter(property)(importlib.import_module(module))\n",
    "            except ModuleNotFoundError as BaseException:\n",
    "                module, period, rest = module.rpartition('.')\n",
    "                property = '.'.join((rest, property)).rstrip('.')\n",
    "                if not module: raise BaseException\n",
    "\n",
    "    @functools.wraps(toolz.map)\n",
    "    def map(callable, object, key=None):\n",
    "        \"\"\"A general `map` function for sequences and containers.\"\"\"\n",
    "        if isinstance(object, typing.Mapping):\n",
    "            if key is not None: object = toolz.keymap(key, object)\n",
    "            return toolz.valmap(forward(callable), object)\n",
    "        return toolz.map(callable, object)\n",
    "            \n",
    "    @functools.wraps(toolz.filter)\n",
    "    def filter(callable, object, key=None):\n",
    "        \"\"\"A general `filter` function for sequences and containers.\"\"\"\n",
    "        if isinstance(object, typing.Mapping):\n",
    "            if key is not None: object = toolz.keyfilter(key, object)\n",
    "            return toolz.valfilter(forward(callable), object)\n",
    "        return toolz.filter(callable, object)\n",
    "\n",
    "    def read(object, *args, **kwargs):\n",
    "        \"\"\"Read files, urls, or yaml.  Always try to parse json.\"\"\"\n",
    "        try: \n",
    "            object = pathlib.Path(object).read_text()\n",
    "            try: return json.loads(object)\n",
    "            except: return objects\n",
    "        except: ...\n",
    "        if urllib.parse.urlparse(object).scheme:\n",
    "            response = __import__('requests').get(object, *args, **kwargs)\n",
    "            try: return response.json()\n",
    "            except: return response.text\n",
    "        return yaml(object)\n",
    "\n",
    "    class juxt(toolz.functoolz.juxt):\n",
    "        def __new__(self, funcs):\n",
    "            if isinstance(funcs, str): funcs = forward(funcs)\n",
    "            if callable(funcs) or not toolz.isiterable(funcs): return funcs\n",
    "            self = super().__new__(self)\n",
    "            return self.__init__(funcs) or self\n",
    "        def __init__(self, object): self.funcs = object\n",
    "        def __call__(self, *args, **kwargs):\n",
    "            if isinstance(self.funcs, typing.Mapping):\n",
    "                object = type(self.funcs)()\n",
    "                for key, value in self.funcs.items():\n",
    "                    if callable(key): key = key(*args, **kwargs)\n",
    "                    if callable(value): value = value(*args, **kwargs)\n",
    "                    object[key] = value\n",
    "                else: return object\n",
    "            if toolz.isiterable(self.funcs): return type(self.funcs)(x(*args, **kwargs) if callable(x) else x for x in self.funcs)                    \n",
    "            if callable(self.funcs): return self.funcs(*args, **kwargs)\n",
    "            return self.funcs\n",
    "\n",
    "    class Ø(BaseException):\n",
    "        def __bool__(self): return False\n",
    "\n",
    "    def write(object, filename): return getattr(pathlib.Path(filename), F\"write_{'bytes' if isinstance(object, bytes) else 'text'}\")(object)\n",
    "\n",
    "    def yaml(object, *, loads=json.loads):\n",
    "        try: from ruamel.yaml import safe_load as loads\n",
    "        except ModuleNotFoundError: \n",
    "            try: from yaml import safe_load as loads\n",
    "            except: ...\n",
    "        return loads(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def stars(callable):\n",
    "        @functools.wraps(callable)\n",
    "        def call(*iter, **kwargs):\n",
    "            args, iter = list(), list(iter)\n",
    "            while iter:\n",
    "                if isinstance(iter[-1], typing.Mapping): kwargs.update(iter.pop())\n",
    "                else: args.extend(iter.pop()) \n",
    "            return callable(*args, **kwargs)        \n",
    "        return call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`\"__main__\"` tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestResults(failed=0, attempted=32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "#### Tests\n",
       "\n",
       "Initializing a composition.\n",
       "\n",
       "    >>> assert λ[:] == λ() == λ[::] == λ[0] == λ[1] \n",
       "    >>> λ[:]\n",
       "    λ(<function I at ...>,)\n",
       "\n",
       "Composing compositions.\n",
       "\n",
       "    >>> λ[callable]\n",
       "    λ(<built-in function callable>,)\n",
       "    >>> assert λ[callable] == λ+callable == callable+λ == λ.pipe(callable)\n",
       "    >>> assert λ[callable] != λ[callable][range]\n",
       "    >>> assert λ.skip() == λ-callable == callable-λ\n",
       "\n",
       "Juxtapositions.\n",
       "\n",
       "    >>> λ[type, str]\n",
       "    λ(<__main__.juxt object at ...>,)\n",
       "    >>> λ[type, str](10)\n",
       "    (<class 'int'>, '10')\n",
       "    >>> λ[{type, str}][type, len](10)\n",
       "    (<class 'set'>, 2)\n",
       "    >>> λ[{'a': type, type: str}](10)\n",
       "    {'a': <class 'int'>, <class 'int'>: '10'}\n",
       "    \n",
       "Mapping.\n",
       "\n",
       "    >>> (λ[range] * type + list)(3)\n",
       "    [<class 'int'>, <class 'int'>, <class 'int'>]\n",
       "    >>> λ[range].map((type, str))[list](3)\n",
       "    [(<class 'int'>, '0'), (<class 'int'>, '1'), (<class 'int'>, '2')]\n",
       "    \n",
       "Filtering\n",
       "\n",
       "    >>> (λ[range] / λ[(3).__lt__, (2).__rfloordiv__][all] + list)(10)\n",
       "    [4, 5, 6, 7, 8, 9]\n",
       "    >>> (λ[range] / (λ[(3).__lt__, (2).__rmod__][all]) + list)(10)\n",
       "    [5, 7, 9]\n",
       "    \n",
       "Filtering Mappings\n",
       "\n",
       "    >>> λ('abc').enumerate().dict().filter('ab'.__contains__)()\n",
       "    {0: 'a', 1: 'b'}\n",
       "    >>> λ('abc').enumerate().dict().filter(λ().pipe(operator.__contains__, 'bc') , (1).__lt__)()\n",
       "    {2: 'c'}\n",
       "    >>> λ('abc').enumerate().dict().keyfilter((1).__lt__)()\n",
       "    {2: 'c'}\n",
       "    \n",
       "Groupby\n",
       "    \n",
       "    >>> assert λ[range] @ (2).__rmod__ == λ[range].groupby((2).__rmod__)\n",
       "    >>> (λ[range] @ (2).__rmod__)(10)\n",
       "    {0: [0, 2, 4, 6, 8], 1: [1, 3, 5, 7, 9]}\n",
       "    \n",
       "Reduce\n",
       "    \n",
       "    >>> assert λ[range]%int.__add__ == λ[range].reduce(int.__add__)\n",
       "    >>> (λ[range] % int.__add__)(10)\n",
       "    45\n",
       "    \n",
       "Conditionals\n",
       "\n",
       "    >>> λ[λ**int+bool, λ**str](10)\n",
       "    (True, False)\n",
       "\n",
       "Forward references.\n",
       "\n",
       "    >>> λ['random.random']()\n",
       "    0...\n",
       "    \n",
       "Loading files.\n",
       "\n",
       "    >>> (λ('2019-10-18-another-bout-with-poser.ipynb').read()[\n",
       "    ... type, λ.itemgetter('cells')[toolz.first].itemgetter('cell_type')\n",
       "    ... ])()\n",
       "    (<class 'dict'>, 'markdown')\n",
       "\n",
       "Syntactic sugar causes cancer of the semicolon.  \n",
       "\n",
       "Feature flags: `λ` has `\"on\" \"off\"` features flags.\n",
       "\n",
       "    >>> λ[range].do(λ+list+print).on()(10)\n",
       "    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
       "    range(0, 10)\n",
       "    >>> λ[range].do(λ+list+print).off()(10)\n",
       "    range(0, 10)\n",
       "    >>> λ[range].do(λ+list+print)[False](10), λ[range].do(λ+list+print)[0](10)\n",
       "    (range(0, 10), range(0, 10))\n",
       "    \n",
       "    \n",
       "Starred functions allows arguments and dictionaries to be defined in iterables.\n",
       "\n",
       "    >>> stars(range)([0,10])\n",
       "    range(0, 10)\n",
       "    >>> stars(λ[dict])(λ[range][reversed][enumerate][[list]](3))\n",
       "    {0: 2, 1: 1, 2: 0}\n",
       "     \n",
       "Some recipes.\n",
       "\n",
       "Load a bunch of notebooks as objects.\n",
       "\n",
       "    >>> λ[λ.glob('*.ipynb').take(2)[list] * [I, λ.read()] + dict + 'pandas.Series'][type, len]()\n",
       "    (<class 'pandas.core.series.Series'>, ...)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    __test__ = globals().get('__test__', {}); __test__[__name__] = \"\"\"\n",
    "    #### Tests\n",
    "    \n",
    "    Initializing a composition.\n",
    "\n",
    "        >>> assert λ[:] == λ() == λ[::] == λ[0] == λ[1] \n",
    "        >>> λ[:]\n",
    "        λ(<function I at ...>,)\n",
    "\n",
    "    Composing compositions.\n",
    "\n",
    "        >>> λ[callable]\n",
    "        λ(<built-in function callable>,)\n",
    "        >>> assert λ[callable] == λ+callable == callable+λ == λ.pipe(callable)\n",
    "        >>> assert λ[callable] != λ[callable][range]\n",
    "        >>> assert λ.skip() == λ-callable == callable-λ\n",
    "\n",
    "    Juxtapositions.\n",
    "\n",
    "        >>> λ[type, str]\n",
    "        λ(<__main__.juxt object at ...>,)\n",
    "        >>> λ[type, str](10)\n",
    "        (<class 'int'>, '10')\n",
    "        >>> λ[{type, str}][type, len](10)\n",
    "        (<class 'set'>, 2)\n",
    "        >>> λ[{'a': type, type: str}](10)\n",
    "        {'a': <class 'int'>, <class 'int'>: '10'}\n",
    "        \n",
    "    Mapping.\n",
    "    \n",
    "        >>> (λ[range] * type + list)(3)\n",
    "        [<class 'int'>, <class 'int'>, <class 'int'>]\n",
    "        >>> λ[range].map((type, str))[list](3)\n",
    "        [(<class 'int'>, '0'), (<class 'int'>, '1'), (<class 'int'>, '2')]\n",
    "        \n",
    "    Filtering\n",
    "    \n",
    "        >>> (λ[range] / λ[(3).__lt__, (2).__rfloordiv__][all] + list)(10)\n",
    "        [4, 5, 6, 7, 8, 9]\n",
    "        >>> (λ[range] / (λ[(3).__lt__, (2).__rmod__][all]) + list)(10)\n",
    "        [5, 7, 9]\n",
    "        \n",
    "    Filtering Mappings\n",
    "    \n",
    "        >>> λ('abc').enumerate().dict().filter('ab'.__contains__)()\n",
    "        {0: 'a', 1: 'b'}\n",
    "        >>> λ('abc').enumerate().dict().filter(λ().pipe(operator.__contains__, 'bc') , (1).__lt__)()\n",
    "        {2: 'c'}\n",
    "        >>> λ('abc').enumerate().dict().keyfilter((1).__lt__)()\n",
    "        {2: 'c'}\n",
    "        \n",
    "    Groupby\n",
    "        \n",
    "        >>> assert λ[range] @ (2).__rmod__ == λ[range].groupby((2).__rmod__)\n",
    "        >>> (λ[range] @ (2).__rmod__)(10)\n",
    "        {0: [0, 2, 4, 6, 8], 1: [1, 3, 5, 7, 9]}\n",
    "        \n",
    "    Reduce\n",
    "        \n",
    "        >>> assert λ[range]%int.__add__ == λ[range].reduce(int.__add__)\n",
    "        >>> (λ[range] % int.__add__)(10)\n",
    "        45\n",
    "        \n",
    "    Conditionals\n",
    "    \n",
    "        >>> λ[λ**int+bool, λ**str](10)\n",
    "        (True, False)\n",
    "    \n",
    "    Forward references.\n",
    "\n",
    "        >>> λ['random.random']()\n",
    "        0...\n",
    "        \n",
    "    Loading files.\n",
    "    \n",
    "        >>> (λ('2019-10-18-another-bout-with-poser.ipynb').read()[\n",
    "        ... type, λ.itemgetter('cells')[toolz.first].itemgetter('cell_type')\n",
    "        ... ])()\n",
    "        (<class 'dict'>, 'markdown')\n",
    "\n",
    "    Syntactic sugar causes cancer of the semicolon.  \n",
    "\n",
    "    Feature flags: `λ` has `\"on\" \"off\"` features flags.\n",
    "\n",
    "        >>> λ[range].do(λ+list+print).on()(10)\n",
    "        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "        range(0, 10)\n",
    "        >>> λ[range].do(λ+list+print).off()(10)\n",
    "        range(0, 10)\n",
    "        >>> λ[range].do(λ+list+print)[False](10), λ[range].do(λ+list+print)[0](10)\n",
    "        (range(0, 10), range(0, 10))\n",
    "        \n",
    "        \n",
    "    Starred functions allows arguments and dictionaries to be defined in iterables.\n",
    "    \n",
    "        >>> stars(range)([0,10])\n",
    "        range(0, 10)\n",
    "        >>> stars(λ[dict])(λ[range][reversed][enumerate][[list]](3))\n",
    "        {0: 2, 1: 1, 2: 0}\n",
    "         \n",
    "    Some recipes.\n",
    "    \n",
    "    Load a bunch of notebooks as objects.\n",
    "    \n",
    "        >>> λ[λ.glob('*.ipynb').take(2)[list] * [I, λ.read()] + dict + 'pandas.Series'][type, len]()\n",
    "        (<class 'pandas.core.series.Series'>, ...)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    import doctest; __name__ == '__main__' and display(doctest.testmod(optionflags=doctest.ELLIPSIS), IPython.display.Markdown(__test__[__name__]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
